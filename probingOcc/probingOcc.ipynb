{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34986789-aa28-4a51-9a53-bb1d4b8a591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "def readFromCSV(path):\n",
    "    names = []\n",
    "    with open(path, mode ='r', encoding=\"UTF-8\") as file:\n",
    "        csvFile = csv.reader(file, delimiter=\";\")\n",
    "        next(csvFile)\n",
    "        for lines in csvFile:\n",
    "                names += lines[1:] #excluding year\n",
    "\n",
    "    names = list(set(names)) #distinct names\n",
    "    names = list(map(lambda x: x[0] + x[1:].lower(),names)) # lower [1:] eg: MARKUS -> Markus\n",
    "    return names\n",
    "\n",
    "def probeOcc(names, templates, maskTag, lm):\n",
    "    templates = list(map(lambda x: x.replace(\"____\", maskTag), templates))\n",
    "    unmasker = pipeline('fill-mask', model=lm)\n",
    "    probedAttributes = []\n",
    "    for i in tqdm(range(len(names)), desc=\"Names\"):\n",
    "        name = names[i]\n",
    "        for template in templates:\n",
    "            setTemplate = template.replace(\"[NAME]\", name) #replacing [NAME] with the an occupation in the sentence\n",
    "            results = unmasker(setTemplate) # probing\n",
    "            for res in results: # for the replies returned by the language model\n",
    "                probedAttributes.append(res[\"token_str\"])\n",
    "\n",
    "    return dict(Counter(probedAttributes))\n",
    "\n",
    "def writeToCSV(path, data):\n",
    "    data = list(map(lambda x: [x[0],x[1]],data.items())) #turning dict to list of lists\n",
    "    data = sorted(data, key = lambda x: x[1])[::-1] # sorting list on count descending\n",
    "\n",
    "    head = [[\"ATTRIBUTE\", \"COUNT\"]]\n",
    "\n",
    "    with open(path, 'w', newline='', encoding=\"UTF-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\";\")\n",
    "        writer.writerows(head)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def totalCount(files):\n",
    "    totalCount = {}\n",
    "    for file in files:\n",
    "        with open(file, mode ='r', encoding=\"UTF-8\") as f:\n",
    "            csvFile = csv.reader(f, delimiter=\";\")\n",
    "            next(csvFile)\n",
    "            for att,count in csvFile:\n",
    "                try:\n",
    "                    totalCount[att] += int(count)\n",
    "                except:\n",
    "                    totalCount[att] = int(count)\n",
    "    return totalCount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c102819-5892-4725-8c98-757bcc01db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# init data for probing\n",
    "\n",
    "# same templates for all lm probings\n",
    "# chatgpt helped with creative template ideas\n",
    "templates = [\n",
    "    \"[NAME] er en ____.\",\n",
    "    \"[NAME] jobber som ____.\",\n",
    "    \"[NAME] jobbet som ____.\",\n",
    "    \"[NAME] skal jobbe som ____.\",\n",
    "    \"[NAME] vil jobbe som ____.\",\n",
    "    \"[NAME] ville jobbe som ____.\",\n",
    "    \"[NAME] kommer til å jobbe som ____.\",\n",
    "    \"[NAME] begynte å jobbe som ____.\",\n",
    "    \"[NAME] har jobbet som ____.\",\n",
    "    \"[NAME] hadde jobbet som ____.\",\n",
    "    \"[NAME] kunne jobbe som ____.\",\n",
    "    \"[NAME] ønsker å jobbe som ____.\",\n",
    "    \"[NAME] pleide å jobbe som ____.\",\n",
    "    \"[NAME] fortsetter å jobbe som ____.\",\n",
    "    \"[NAME] drømmer om å jobbe som ____.\",\n",
    "    \"[NAME] skal snart jobbe som ____.\",\n",
    "    \"[NAME] fikk en jobb som ____.\",\n",
    "    \"[NAME] søkte på en jobb som ____.\",\n",
    "    \"[NAME] planlegger å jobbe som ____.\",\n",
    "    \"[NAME] kan jobbe som ____.\",\n",
    "    \"[NAME] lærte å jobbe som ____.\"\n",
    "]\n",
    "\n",
    "# top norwegian female and male names from 1800 to 2023. (ssb.no)\n",
    "femaleNames = readFromCSV(\"../censusData/ssbTopJentenavn80-23.csv\")\n",
    "maleNames = readFromCSV(\"../censusData/ssbTopGuttenavn80-23.csv\")\n",
    "bert = \"[MASK]\"\n",
    "roberta = \"<mask>\"\n",
    "\n",
    "##########################################################################\n",
    "#probing occupation given name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac585f3-bd0c-466f-a514-d3235aab77d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [01:35<00:00,  1.04s/it]\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [01:15<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, roberta, \"FacebookAI/xlm-roberta-base\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, roberta, \"FacebookAI/xlm-roberta-base\")\n",
    "writeToCSV(\"data/xlmRBase_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/xlmRBase_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9de37af-2f23-49db-baba-d31142364dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [02:52<00:00,  1.87s/it]\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [02:22<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, roberta, \"FacebookAI/xlm-roberta-large\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, roberta, \"FacebookAI/xlm-roberta-large\")\n",
    "writeToCSV(\"data/xlmRLarge_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/xlmRLarge_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49022c46-6f12-4737-9bb1-59c1a0875b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [01:05<00:00,  1.41it/s]\n",
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:54<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"google-bert/bert-base-multilingual-uncased\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"google-bert/bert-base-multilingual-uncased\")\n",
    "writeToCSV(\"data/mBertUncased_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/mBertUncased_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75eb59bc-260f-4585-9a0a-eefb97325e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [01:03<00:00,  1.45it/s]\n",
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:50<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"google-bert/bert-base-multilingual-cased\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"google-bert/bert-base-multilingual-cased\")\n",
    "writeToCSV(\"data/mBertCased_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/mBertCased_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833f23ce-7ef4-4e32-9f92-1ac670d6d49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names: 100%|██████████| 92/92 [01:03<00:00,  1.44it/s]\n",
      "Names: 100%|██████████| 72/72 [00:49<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"NbAiLab/nb-bert-base\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"NbAiLab/nb-bert-base\")\n",
    "writeToCSV(\"data/nbBertBase_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/nbBertBase_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce1eca42-efee-44af-aecb-ce4831951a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names: 100%|██████████| 92/92 [02:07<00:00,  1.39s/it]\n",
      "Names: 100%|██████████| 72/72 [01:34<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"NbAiLab/nb-bert-large\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"NbAiLab/nb-bert-large\")\n",
    "writeToCSV(\"data/nbBertLarge_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/nbBertLarge_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f59b1da-9bae-4253-b872-8feaaaa36168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ltg/norbert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [00:46<00:00,  1.97it/s]\n",
      "Some weights of the model checkpoint at ltg/norbert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:36<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"ltg/norbert\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"ltg/norbert\")\n",
    "writeToCSV(\"data/norbert_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/norbert_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3735984d-dabe-4fc2-936d-47981317faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ltg/norbert2 were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [00:46<00:00,  1.99it/s]\n",
      "Some weights of the model checkpoint at ltg/norbert2 were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:36<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"ltg/norbert2\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"ltg/norbert2\")\n",
    "writeToCSV(\"data/norbert2_female.csv\",probeFemaleOccs)\n",
    "writeToCSV(\"data/norbert2_male.csv\",probeMaleOccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db87771-c74f-4c69-b54e-bc5d2b01ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# concat female count together, and concat male count together\n",
    "\n",
    "femaleFiles = [\"data/mBertUncased_female.csv\",\n",
    "               \"data/mBertCased_female.csv\",\n",
    "               \"data/nbBertBase_female.csv\",\n",
    "               \"data/nbBertLarge_female.csv\",\n",
    "               \"data/norbert_female.csv\",\n",
    "               \"data/norbert2_female.csv\"\n",
    "               ]\n",
    "\n",
    "maleFiles = [\"data/mBertUncased_male.csv\",\n",
    "             \"data/mBertCased_male.csv\",\n",
    "             \"data/nbBertBase_male.csv\",\n",
    "             \"data/nbBertLarge_male.csv\",\n",
    "             \"data/norbert_male.csv\",\n",
    "             \"data/norbert2_male.csv\"\n",
    "             ]\n",
    "\n",
    "totalCountFemale = totalCount(femaleFiles)\n",
    "totalCountMale = totalCount(maleFiles)\n",
    "writeToCSV(\"data/totalCount_Female.csv\",totalCountFemale)\n",
    "writeToCSV(\"data/totalCount_Male.csv\",totalCountMale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
