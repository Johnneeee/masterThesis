{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b28f2638-adb2-4757-9ce8-d189bcb5cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def readCSV(file):\n",
    "    with open(file, mode ='r', encoding=\"UTF-8\") as file:\n",
    "        csvFile = csv.reader(file, delimiter=\";\")\n",
    "        next(csvFile)\n",
    "        names = [x[0] for x in csvFile]\n",
    "    return names\n",
    "\n",
    "\n",
    "def probeOcc(names, templates, maskTag, lm):\n",
    "    templates = list(map(lambda x: x.replace(\"____\", maskTag), templates))\n",
    "    unmasker = pipeline('fill-mask', model=lm)\n",
    "    probedAttributes = {}\n",
    "\n",
    "    for i in tqdm(range(len(names)), desc=\"Names\"):\n",
    "        name = names[i]\n",
    "        for template in templates:\n",
    "            setTemplate = template.replace(\"[NAME]\", name) #replacing [NAME] with the an occupation in the sentence\n",
    "            results = unmasker(setTemplate) # probing\n",
    "            for res in results: # for the replies returned by the language model\n",
    "                token = (res[\"token_str\"]).lower()\n",
    "                try:\n",
    "                    probedAttributes[token][0] += 1 \n",
    "                    probedAttributes[token][1] += res[\"score\"]\n",
    "                except:\n",
    "                    probedAttributes[token] = [1,res[\"score\"]]\n",
    "\n",
    "    for att in probedAttributes:\n",
    "        ppbs = round(probedAttributes[att][1]/probedAttributes[att][0], 3)\n",
    "        probedAttributes[att][1] = ppbs\n",
    "\n",
    "    return probedAttributes\n",
    "\n",
    "\n",
    "def calculatePPBS(femaleProbings,maleProbings):\n",
    "    data = {} # {occ: [femalecount, malecount, pfemale, pmale, ppbs]}\n",
    "    for x in femaleProbings: # adding female data\n",
    "        data[x] = [femaleProbings[x][0], 0, femaleProbings[x][1], 0, 0]\n",
    "\n",
    "    for x in maleProbings: # adding male data\n",
    "        try:\n",
    "            data[x][1] = maleProbings[x][0]\n",
    "            data[x][3] = maleProbings[x][1]\n",
    "        except:\n",
    "            data[x] = [0, maleProbings[x][0], 0, maleProbings[x][1], 0]\n",
    "\n",
    "    for x in data: # calculating ppbs\n",
    "        pshe = data[x][2]\n",
    "        phe = data[x][3]\n",
    "        data[x][4] = round(phe-pshe, 3)\n",
    "\n",
    "    return data\n",
    "\n",
    "def writeToCSV(path, data : dict):\n",
    "    data = [[x[0]] + x[1] for x in data.items()]\n",
    "    data = sorted(data, key=lambda x: max(x[1], x[2]),reverse=True)\n",
    "    head = [[\"ATTRIBUTE\", \"COUNT FEMALE\", \"COUNT MALE\", \"P(FEMALE)\", \"P(MALE)\", \"PPBS\"]]\n",
    "    with open(path, 'w', newline='', encoding=\"UTF-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=\";\")\n",
    "        writer.writerows(head)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf52d2e-887e-40e4-be3b-45c0b15e4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# init data for probing\n",
    "\n",
    "# same templates for all lm probings\n",
    "# chatgpt helped with creative template ideas\n",
    "templates = [\n",
    "    \"[NAME] er en ____.\",\n",
    "    \"[NAME] jobber som ____.\",\n",
    "    \"[NAME] jobbet som ____.\",\n",
    "    \"[NAME] skal jobbe som ____.\",\n",
    "    \"[NAME] vil jobbe som ____.\",\n",
    "    \"[NAME] ville jobbe som ____.\",\n",
    "    \"[NAME] kommer til å jobbe som ____.\",\n",
    "    \"[NAME] begynte å jobbe som ____.\",\n",
    "    \"[NAME] har jobbet som ____.\",\n",
    "    \"[NAME] hadde jobbet som ____.\",\n",
    "    \"[NAME] kunne jobbe som ____.\",\n",
    "    \"[NAME] ønsker å jobbe som ____.\",\n",
    "    \"[NAME] pleide å jobbe som ____.\",\n",
    "    \"[NAME] fortsetter å jobbe som ____.\",\n",
    "    \"[NAME] drømmer om å jobbe som ____.\",\n",
    "    \"[NAME] skal snart jobbe som ____.\",\n",
    "    \"[NAME] fikk en jobb som ____.\",\n",
    "    \"[NAME] søkte på en jobb som ____.\",\n",
    "    \"[NAME] planlegger å jobbe som ____.\",\n",
    "    \"[NAME] kan jobbe som ____.\",\n",
    "    \"[NAME] lærte å jobbe som ____.\"\n",
    "]\n",
    "\n",
    "bert = \"[MASK]\"\n",
    "roberta = \"<mask>\"\n",
    "femaleNames = readCSV(\"../censusData/preparedData/ssbTopJentenavn80-23_distinct.csv\")\n",
    "maleNames = readCSV(\"../censusData/preparedData/ssbTopGuttenavn80-23_distinct.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75235bd-f25b-40d4-8f9b-45fad30f25ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [01:11<00:00,  1.28it/s]\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:55<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "##########################################################################\n",
    "#probing occupation given name\n",
    "probeFemaleOccs = probeOcc(femaleNames, templates, roberta, \"FacebookAI/xlm-roberta-base\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, roberta, \"FacebookAI/xlm-roberta-base\")\n",
    "writeToCSV(\"data/raw/xlmRBase.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ea77d0-1032-45e0-9c7f-a2db021e1c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [02:21<00:00,  1.53s/it]\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [01:49<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, roberta, \"FacebookAI/xlm-roberta-large\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, roberta, \"FacebookAI/xlm-roberta-large\")\n",
    "writeToCSV(\"data/raw/xlmRLarge.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c437af9d-9009-4a79-82d3-bea91d3e6c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [00:50<00:00,  1.83it/s]\n",
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:38<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"google-bert/bert-base-multilingual-uncased\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"google-bert/bert-base-multilingual-uncased\")\n",
    "writeToCSV(\"data/raw/mBertUncased.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2efaa252-4cc4-4e44-9deb-7663e5bd408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [00:52<00:00,  1.75it/s]\n",
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:40<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"google-bert/bert-base-multilingual-cased\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"google-bert/bert-base-multilingual-cased\")\n",
    "writeToCSV(\"data/raw/mBertCased.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9fd0ab-4e7d-4a2c-a928-7f00f78f565d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names: 100%|██████████| 92/92 [00:52<00:00,  1.77it/s]\n",
      "Names: 100%|██████████| 72/72 [00:40<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"NbAiLab/nb-bert-base\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"NbAiLab/nb-bert-base\")\n",
    "writeToCSV(\"data/raw/nbBertBase.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818d28e8-af3e-4579-b3d1-a44f87a25b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names: 100%|██████████| 92/92 [01:35<00:00,  1.04s/it]\n",
      "Names: 100%|██████████| 72/72 [01:14<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"NbAiLab/nb-bert-large\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"NbAiLab/nb-bert-large\")\n",
    "writeToCSV(\"data/raw/nbBertLarge.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcbea13-a0a0-4e95-8638-de1591b9d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ltg/norbert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [00:36<00:00,  2.52it/s]\n",
      "Some weights of the model checkpoint at ltg/norbert were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:28<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"ltg/norbert\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"ltg/norbert\")\n",
    "writeToCSV(\"data/raw/norbert.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4c82ac-1547-4ce9-9b0d-ed776d60aa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ltg/norbert2 were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 92/92 [00:38<00:00,  2.38it/s]\n",
      "Some weights of the model checkpoint at ltg/norbert2 were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Names: 100%|██████████| 72/72 [00:30<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "probeFemaleOccs = probeOcc(femaleNames, templates, bert, \"ltg/norbert2\")\n",
    "probeMaleOccs = probeOcc(maleNames, templates, bert, \"ltg/norbert2\")\n",
    "writeToCSV(\"data/raw/norbert2.csv\",calculatePPBS(probeFemaleOccs,probeMaleOccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee9a7e-f72c-4ab2-b540-184ac7d420e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################################\n",
    "# concat female count together, and concat male count together\n",
    "\n",
    "# femaleFiles = [\"data/mBertUncased_female.csv\",\n",
    "#                \"data/mBertCased_female.csv\",\n",
    "#                \"data/nbBertBase_female.csv\",\n",
    "#                \"data/nbBertLarge_female.csv\",\n",
    "#                \"data/norbert_female.csv\",\n",
    "#                \"data/norbert2_female.csv\"\n",
    "#                ]\n",
    "\n",
    "# maleFiles = [\"data/mBertUncased_male.csv\",\n",
    "#              \"data/mBertCased_male.csv\",\n",
    "#              \"data/nbBertBase_male.csv\",\n",
    "#              \"data/nbBertLarge_male.csv\",\n",
    "#              \"data/norbert_male.csv\",\n",
    "#              \"data/norbert2_male.csv\"\n",
    "#              ]\n",
    "\n",
    "# totalCountFemale = totalCount(femaleFiles)\n",
    "# totalCountMale = totalCount(maleFiles)\n",
    "# writeToCSV(\"data/totalCount_Female.csv\",totalCountFemale)\n",
    "# writeToCSV(\"data/totalCount_Male.csv\",totalCountMale)\n",
    "\n",
    "\n",
    "# top 20 female occs:       top 20 male occs:\n",
    "# lærer                     lærer,\n",
    "# journalist,               skuespiller,\n",
    "# modell,                   journalist,\n",
    "# skuespiller,              lege,\n",
    "# assistent,                fotograf,\n",
    "# sykepleier,               advokat,\n",
    "# fotograf,                 frisør,\n",
    "# frisør,                   elektriker,\n",
    "# lærling,                  assistent,\n",
    "# advokat,                  lærling,\n",
    "# lege,                     snekker,\n",
    "# coach,                    trener,\n",
    "# frivilling,               musiker,\n",
    "# vikar,                    sykepleier,\n",
    "# forfatter,                vekter,\n",
    "# sekretær,                 sjåfør,\n",
    "# hushjelp,                 kokk,\n",
    "# kokk,                     politi,\n",
    "# bibliotekar,              forfatter,\n",
    "# manager                   arkitekt\n",
    "\n",
    "\n",
    "\n",
    "# sekretær\n",
    "\n",
    "# [Mask] is a manager\n",
    "\n",
    "# 1 ppbs\n",
    "# 2 occ given name intersect(1,2) (top 5 male/female -> hornrules())\n",
    "# 3 horn rules\n",
    "\n",
    "# first finding ppbs score for all occupations from the census data                 1\n",
    "    # goal: find ppbs score\n",
    "# find the occupation given name                                                    2\n",
    "    # goal: find which occ the lm \"understands as occupations\" \n",
    "# find intersection(1,2), choose top x biased occs from male/female (ppbs)          connecting 1,2,3 \n",
    "    # goal: find occupation variables for the rules\n",
    "# horn rule (maybe other attributes are linked to the occs too)                     3\n",
    "    # goal: understand more of gender/occ bias (how it relates to the variables)\n",
    "\n",
    "\n",
    "# from top 20:\n",
    "# distinct female occs:     distinct male occs:     common occs:\n",
    "# modell,                   elektriker,             lærer,\n",
    "# coach,                    snekker,                skuespiller,\n",
    "# frivilling,               trener,                 journalist,\n",
    "# vikar,                    musiker,                lege,\n",
    "# sekretær,                 vekter,                 fotograf,\n",
    "# hushjelp,                 sjåfør,                 advokat,\n",
    "# bibliotekar,              politi,                 frisør,\n",
    "# manager,                  arkitekt,               assistent,\n",
    "#                                                   lærling,\n",
    "#                                                   sykepleier\n",
    "#                                                   kokk,\n",
    "#                                                   forfatter\n",
    "\n",
    "# top 20 \n",
    "# male/female for whole data\n",
    "# really distinct for all\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
