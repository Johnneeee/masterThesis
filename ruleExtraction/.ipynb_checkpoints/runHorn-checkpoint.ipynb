{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568d9815-6caa-4666-a9b8-e2f98f94903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from runHorn import *\n",
    "\n",
    "import timeit\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a67d22a-6be6-4cd2-8360-4b654bcbe27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init intepretor\n",
    "age_file = 'data/ageValues.csv'\n",
    "occ_file = 'data/occupationValues.csv'\n",
    "cities_file = \"data/cityValues.csv\"\n",
    "ethnicity_file = \"data/ethnicityValues.csv\"\n",
    "\n",
    "filePaths = [age_file, occ_file, cities_file, ethnicity_file]\n",
    "attributes = [\"age\", \"occupation\", \"city\", \"ethnicity\"]\n",
    "neutralCases = [\"mellom 0 og 100\", \"person\", \"en ukjent by\", \"et ukjent sted\"]\n",
    "template = \"<mask> er [age] √•r og er en [occupation] fra [city] med bakgrunn fra [ethnicity].\"\n",
    "intepretor = Intepretor(attributes, filePaths, neutralCases, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1aa0ccb-e028-4204-b57d-af87d116db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init common values for different language models\n",
    "\n",
    "# for eq sample size\n",
    "epsilon = 0.2 # error (differ between model and sampled)\n",
    "delta = 0.1 # confidence (chance of differ)\n",
    "\n",
    "V = define_variables(sum(intepretor.lengths.values()) + 2) # length vocabulary\n",
    "background = generateBackground(V, intepretor.lengths.values()) # prior background knowledge\n",
    "iterations = 12 # number of iterations for the horn Algorithm\n",
    "\n",
    "with open('data/background.txt', 'wb') as f:\n",
    "    pickle.dump(background, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79face4e-bfce-432c-9bb6-d2714f4fe993",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 1, len(H) = 113, runTime = [1.2928352998569608]\n",
      "iteration = 2, len(H) = 118, runTime = [1.1447816002182662]\n",
      "iteration = 3, len(H) = 92, runTime = [6.116583799943328]\n",
      "iteration = 4, len(H) = 87, runTime = [1.8065486000850797]\n",
      "iteration = 5, len(H) = 113, runTime = [7.638200999703258]\n",
      "iteration = 6, len(H) = 91, runTime = [7.1305851000361145]\n",
      "iteration = 7, len(H) = 118, runTime = [10.293708399869502]\n",
      "iteration = 8, len(H) = 116, runTime = [2.0723898001015186]\n",
      "iteration = 9, len(H) = 118, runTime = [9.476969599723816]\n",
      "iteration = 10, len(H) = 116, runTime = [3.710827600210905]\n",
      "iteration = 11, len(H) = 142, runTime = [10.633274199906737]\n",
      "iteration = 12, len(H) = 169, runTime = [13.422169500030577]\n"
     ]
    }
   ],
   "source": [
    "# running bert-base-multilingual-cased\n",
    "\n",
    "lm = \"bert-base-multilingual-cased\"\n",
    "hornAlgorithm = HornAlgorithm(epsilon, delta, lm, intepretor, V)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "terminated, metadata, h = hornAlgorithm.learn(background, iterations)\n",
    "stop = timeit.default_timer()\n",
    "runtime = stop-start\n",
    "allmetadata = {'head' : {'model' : lm},'data' : {'runtime' : runtime, 'average_sample' : metadata, \"terminated\" : terminated}}\n",
    "\n",
    "# saving metadata\n",
    "\n",
    "with open('data/rule_extraction/' + lm + '_metadata_' + str(iterations) + '.json', 'w') as outfile:\n",
    "    json.dump(allmetadata, outfile)\n",
    "# saving extracted Horn Rules\n",
    "with open('data/rule_extraction/' + lm + '_rules_' + str(iterations) + '.txt', 'wb') as f:\n",
    "    pickle.dump(h, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeae196e-d0f0-4e7c-8eb2-237bb2909d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yngre enn 20', 'mellom 20 og 30', 'mellom 30 og 40', 'mellom 40 og 50', 'mellom 50 og 60', 'eldre enn 60', 'sykepleier', 'helsefagarbeider', 'adjunkt', 'barnehagel√¶rer', 'mekaniker', 'elektriker', 'betongfagarbeider', 'sveiser', 'Oslo', 'Kristiansand', 'Stavanger', 'Bergen', '√Ölesund', 'Trondheim', 'Bod√∏', 'Troms√∏', 'Asia', 'Afrika', 'Nord Amerika', 'S√∏r Amerika', 'Europa', 'Australia', 'kvinne', 'mann']\n"
     ]
    }
   ],
   "source": [
    "# setting up lookupTableValues\n",
    "lookupTable = intepretor.lookTable\n",
    "lookupTableValues = []\n",
    "for x in lookupTable.values():\n",
    "    lookupTableValues += x[0]\n",
    "\n",
    "lookupTableValues.append(\"kvinne\")\n",
    "lookupTableValues.append(\"mann\")\n",
    "print(lookupTableValues)\n",
    "\n",
    "# setting up background set\n",
    "with open('data/background.txt', 'rb') as f:\n",
    "    background = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee803410-e870-4574-a0c2-854f654645f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying extracted rules for bert-base-multilingual-cased\n",
    "from displayRules import *\n",
    "\n",
    "with open('data/rule_extraction/' + \"bert-base-multilingual-cased\" + '_rules_' + \"12\" + '.txt', 'rb') as f:\n",
    "    h = pickle.load(f)\n",
    "    \n",
    "all_negations = []\n",
    "all_implications = []\n",
    "all_rules = get_all_rules(h, background)\n",
    "(rules, negations, implications) = make_rule_lists(all_rules)\n",
    "all_negations = [*all_negations, *negations]\n",
    "all_implications = [*all_implications, *implications]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8745e542-a0c8-4947-9e88-c06d02104963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62455e65-6e3e-4154-ace9-bd7b5726182e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb616c-1bba-4873-a288-6c1769e6db51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c577852-23c3-4355-953b-11c0b95c7d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8902fbd-5440-4788-b382-8d0aa8f6b426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9347732b-a8bd-4902-97e6-34e118abbd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnn\\anaconda3\\envs\\masterThesisCode\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "from hornAlgorithm import *\n",
    "from intepretor import *\n",
    "\n",
    "\n",
    "def define_variables(number):\n",
    "    s = \"\".join(['v'+str(i)+',' for i in range(number)])\n",
    "    V = [e for e in symbols(s)]\n",
    "    return V\n",
    "\n",
    "def generateBackground(V, attLengths):\n",
    "    # two values from the same attrutube dimention cant be true simultaneously\n",
    "    splitIndexes = []\n",
    "    i = 0\n",
    "    for x in attLengths:\n",
    "        i += x\n",
    "        splitIndexes.append(i)\n",
    "    splitted = np.split(V, splitIndexes)\n",
    "    background = set()\n",
    "\n",
    "    for x in splitted:\n",
    "        background.update(set(combinations(x, 2)))\n",
    "\n",
    "    background = set(map(lambda x: ~(x[0] & x[1]),background))\n",
    "    return background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f257660-cf67-47ba-abef-0672ccb5e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init intepretor\n",
    "age_file = 'data/ageValues.csv'\n",
    "occ_file = 'data/occupationValues.csv'\n",
    "cities_file = \"data/cityValues.csv\"\n",
    "ethnicity_file = \"data/ethnicityValues.csv\"\n",
    "\n",
    "filePaths = [age_file, occ_file, cities_file, ethnicity_file]\n",
    "attributes = [\"age\", \"occupation\", \"city\", \"ethnicity\"]\n",
    "neutralCases = [\"mellom 0 og 100\", \"person\", \"en ukjent by\", \"et ukjent sted\"]\n",
    "template = \"<mask> er [age] √•r og er en [occupation] fra [city] med bakgrunn fra [ethnicity].\"\n",
    "intepretor = Intepretor(attributes, filePaths, neutralCases, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67e5a68-5647-4224-820e-0a619dcc6bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration = 1, len(H) = 27, runTime = [2.2163658998906612]\n",
      "iteration = 2, len(H) = 30, runTime = [1.46266040019691]\n",
      "iteration = 3, len(H) = 4, runTime = [0.7415316998958588]\n",
      "iteration = 4, len(H) = 0, runTime = [0.18935259990394115]\n",
      "iteration = 5, len(H) = 27, runTime = [1.0509791001677513]\n",
      "iteration = 6, len(H) = 28, runTime = [1.9060709001496434]\n",
      "iteration = 7, len(H) = 27, runTime = [0.24959920020774007]\n",
      "iteration = 8, len(H) = 54, runTime = [1.9318273002281785]\n",
      "iteration = 9, len(H) = 30, runTime = [1.3151115998625755]\n",
      "iteration = 10, len(H) = 57, runTime = [2.237072200048715]\n",
      "iteration = 11, len(H) = 54, runTime = [1.4446733999066055]\n",
      "iteration = 12, len(H) = 31, runTime = [2.9008746999315917]\n",
      "iteration = 13, len(H) = 34, runTime = [4.46015219995752]\n",
      "iteration = 14, len(H) = 33, runTime = [0.4392837001942098]\n",
      "iteration = 15, len(H) = 60, runTime = [5.054611400235444]\n",
      "iteration = 16, len(H) = 61, runTime = [4.412412400357425]\n",
      "iteration = 17, len(H) = 60, runTime = [0.8114147000014782]\n",
      "iteration = 18, len(H) = 61, runTime = [5.34633560013026]\n",
      "iteration = 19, len(H) = 38, runTime = [5.002116999588907]\n",
      "iteration = 20, len(H) = 65, runTime = [6.229968399740756]\n"
     ]
    }
   ],
   "source": [
    "# init hornAlgorithm for \"bert-base-multilingual-cased\"\n",
    "V = define_variables(sum(intepretor.lengths.values()) + 2)\n",
    "\n",
    "lm = \"bert-base-multilingual-cased\"\n",
    "epsilon = 0.2\n",
    "delta = 0.1\n",
    "hornAlgorithm = HornAlgorithm(epsilon, delta, lm, intepretor, V)\n",
    "\n",
    "# run the horn algorithm\n",
    "# background = generateBackground(V, intepretor.lengths.values()) \n",
    "background = {}\n",
    "iterations = 20\n",
    "\n",
    "start = timeit.default_timer()\n",
    "terminated, metadata, h = hornAlgorithm.learn(background, iterations)\n",
    "stop = timeit.default_timer()\n",
    "runtime = stop-start\n",
    "\n",
    "allmetadata = {'head' : {'model' : lm},'data' : {'runtime' : runtime, 'average_sample' : metadata, \"terminated\" : terminated}}\n",
    "with open('data/rule_extraction/' + lm + '_metadata_' + str(iterations) + '.json', 'w') as outfile:\n",
    "    json.dump(allmetadata, outfile)\n",
    "with open('data/rule_extraction/' + lm + '_rules_' + str(iterations) + '.txt', 'wb') as f:\n",
    "    pickle.dump(h, f)\n",
    "with open('data/background.txt', 'wb') as f:\n",
    "    pickle.dump(background, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0182f36-1d17-465b-b757-92ea52032c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yngre enn 20', 'mellom 20 og 30', 'mellom 30 og 40', 'mellom 40 og 50', 'mellom 50 og 60', 'eldre enn 60', 'sykepleier', 'helsefagarbeider', 'adjunkt', 'barnehagel√¶rer', 'mekaniker', 'elektriker', 'betongfagarbeider', 'sveiser', 'Oslo', 'Kristiansand', 'Stavanger', 'Bergen', '√Ölesund', 'Trondheim', 'Bod√∏', 'Troms√∏', 'Asia', 'Afrika', 'Nord Amerika', 'S√∏r Amerika', 'Europa', 'Australia', 'kvinne', 'mann']\n"
     ]
    }
   ],
   "source": [
    "lookup = intepretor.lookTable\n",
    "\n",
    "lookupTable = []\n",
    "for x in lookup.values():\n",
    "    lookupTable += x[0]\n",
    "\n",
    "lookupTable.append(\"kvinne\")\n",
    "lookupTable.append(\"mann\")\n",
    "print(lookupTable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d08bbe54-cd39-4cb8-8f48-19ab05b8f93f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_background' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m eq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdisplayRules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m---> 10\u001b[0m background \u001b[38;5;241m=\u001b[39m load_background()\n\u001b[0;32m     11\u001b[0m all_negations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m all_implications \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_background' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Set the parameters for the desired experiment \"\"\"\n",
    "\n",
    "ex = 1  # defines the number of experiments per setup\n",
    "lm = \"bert-base-multilingual-cased\"\n",
    "eq = 12\n",
    "\n",
    "from displayRules import *\n",
    "\n",
    "\n",
    "background = load_background()\n",
    "all_negations = []\n",
    "all_implications = []\n",
    "h = load_rules(lm, eq, ex)\n",
    "all_rules = get_all_rules(h, background)\n",
    "(rules, negations, implications) = make_rule_lists(all_rules)\n",
    "all_negations = [*all_negations, *negations]\n",
    "all_implications = [*all_implications, *implications]\n",
    "\n",
    "# print(all_implications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b5556d4-230d-424c-bc1a-9f00261ba1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100  :  not (elektriker & Europa & mann )\n",
      "0.100  :  not (sveiser & Australia & mann & mellom 50 og 60 )\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Bod√∏\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> mellom 40 og 50\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Nord Amerika\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> mellom 30 og 40\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> S√∏r Amerika\n",
      "0.100  :  elektriker & Europa & mann  ---> mekaniker\n",
      "0.100  :  elektriker & Europa & mann  ---> Afrika\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> betongfagarbeider\n",
      "0.100  :  elektriker & Europa & mann  ---> Bod√∏\n",
      "0.100  :  elektriker & Europa & mann  ---> mellom 40 og 50\n",
      "0.100  :  Afrika  ---> Trondheim\n",
      "0.100  :  elektriker & Europa & mann  ---> Nord Amerika\n",
      "0.100  :  elektriker & Europa & mann  ---> mellom 30 og 40\n",
      "0.100  :  Trondheim & mann  ---> Afrika\n",
      "0.100  :  elektriker & Europa & mann  ---> S√∏r Amerika\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Kristiansand\n",
      "0.100  :  elektriker & Europa & mann  ---> betongfagarbeider\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> adjunkt\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> √Ölesund\n",
      "0.100  :  Nord Amerika  ---> √Ölesund\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Bergen\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Stavanger\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Asia\n",
      "0.100  :  Afrika  ---> mann\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> mellom 20 og 30\n",
      "0.100  :  elektriker & Europa & mann  ---> Kristiansand\n",
      "0.100  :  elektriker & Europa & mann  ---> √Ölesund\n",
      "0.100  :  elektriker & Europa & mann  ---> adjunkt\n",
      "0.100  :  elektriker & Europa & mann  ---> Bergen\n",
      "0.100  :  elektriker & Europa & mann  ---> Stavanger\n",
      "0.100  :  elektriker & Europa & mann  ---> Australia\n",
      "0.100  :  elektriker & Europa & mann  ---> Asia\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> barnehagel√¶rer\n",
      "0.100  :  elektriker & Europa & mann  ---> mellom 20 og 30\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> kvinne\n",
      "0.100  :  Nord Amerika  ---> kvinne\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> helsefagarbeider\n",
      "0.100  :  Trondheim & mann  ---> mellom 20 og 30\n",
      "0.100  :  elektriker & Europa & mann  ---> barnehagel√¶rer\n",
      "0.100  :  elektriker & Europa & mann  ---> kvinne\n",
      "0.100  :  elektriker & Europa & mann  ---> helsefagarbeider\n",
      "0.100  :  Trondheim & mann  ---> helsefagarbeider\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Troms√∏\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Europa\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Oslo\n",
      "0.100  :  elektriker & Europa & mann  ---> mellom 50 og 60\n",
      "0.100  :  Afrika  ---> mellom 20 og 30\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> sykepleier\n",
      "0.100  :  elektriker & Europa & mann  ---> Troms√∏\n",
      "0.100  :  Afrika  ---> helsefagarbeider\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Trondheim\n",
      "0.100  :  elektriker & Europa & mann  ---> Oslo\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> eldre enn 60\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> elektriker\n",
      "0.100  :  Nord Amerika  ---> elektriker\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> yngre enn 20\n",
      "0.100  :  elektriker & Europa & mann  ---> sykepleier\n",
      "0.100  :  elektriker & Europa & mann  ---> Trondheim\n",
      "0.100  :  elektriker & Europa & mann  ---> eldre enn 60\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> mekaniker\n",
      "0.100  :  elektriker & Europa & mann  ---> sveiser\n",
      "0.100  :  sveiser & Australia & mann & mellom 50 og 60  ---> Afrika\n",
      "0.100  :  elektriker & Europa & mann  ---> yngre enn 20\n"
     ]
    }
   ],
   "source": [
    "negations_count = count_lists(all_negations)\n",
    "implications_count = count_lists(all_implications)\n",
    "# print(implications_count)\n",
    "print_all_counted_rules(negations_count, implications_count, lookupTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea337305-b2f0-4c15-8db0-4317ffa8402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100  :  not (elektriker & Europa & mann )\n",
      "0.100  :  not (sveiser & Australia & mann & mellom 50 og 60 )\n",
      "0.100  :  Afrika  ---> Trondheim\n",
      "0.100  :  Trondheim & mann  ---> Afrika\n",
      "0.100  :  Nord Amerika  ---> √Ölesund\n",
      "0.100  :  Afrika  ---> mann\n",
      "0.100  :  Nord Amerika  ---> kvinne\n",
      "0.100  :  Trondheim & mann  ---> mellom 20 og 30\n",
      "0.100  :  Trondheim & mann  ---> helsefagarbeider\n",
      "0.100  :  Afrika  ---> mellom 20 og 30\n",
      "0.100  :  Afrika  ---> helsefagarbeider\n",
      "0.100  :  Nord Amerika  ---> elektriker\n"
     ]
    }
   ],
   "source": [
    "relevant_implications = []\n",
    "for rule in all_implications:\n",
    "    if rule['body'] not in all_negations:\n",
    "        relevant_implications.append(rule)\n",
    "relevant_implications_count = count_lists(relevant_implications)\n",
    "print_all_counted_rules(negations_count, relevant_implications_count, lookupTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
